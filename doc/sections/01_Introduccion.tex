\chapter{Introducción}\label{cap:introduccion}

En las últimas décadas, la inteligencia artificial (IA) se ha convertido en una tecnología ampliamente conocida y utilizada. Esto ha ocurrido en gran medida gracias al desarrollo de técnicas de aprendizaje automático (machine learning) y al auge de las redes neuronales artificiales. Inicialmente inspiradas en el cerebro humano, estas estructuras de computación han demostrado ser capaces de resolver problemas complejos en áreas como el reconocimiento de patrones, como el análisis forense de escritura manuscrita \cite{examples_nn__kulik_2009} o la interpretación de secuencias del ADN \cite{nn_dna_sequences__snyder_1993}; el procesamiento de lenguaje natural, utilizado en aplicaciones como la traducción automática entre idiomas \cite{machine_translation__mahata_2019} y la implementación de chatbots para atención al cliente automatizada \cite{chatbot_customer_service__nuruzzaman_2018}; y la visión por computadora, clave en tecnologías como el reconocimiento facial para desbloquear dispositivos móviles \cite{conv_nn_face_recog__chowanda_2019} o la conducción autónoma de vehículos mediante SLAM (Simultaneous Localization and Mapping) y detección de obstáculos en tiempo real \cite{slam_vehicles__saleem_2023}. Sin embargo, no todas las redes neuronales son iguales, su diseño y eficacia dependen de la arquitectura elegida y del tipo de datos que deben procesar, siendo este el principal motivo de existencia de tan diferentes diseños arquitectónicos.

En un mundo donde la demanda de sistemas de IA eficientes y explicables crece exponencialmente, comprender las diferencias entre los pilares de las redes neuronales se vuelve esencial tanto para investigadores como para profesionales del ámbito tecnológico.

{\color{red} EXPANDIR INTRODUCCIÓN}